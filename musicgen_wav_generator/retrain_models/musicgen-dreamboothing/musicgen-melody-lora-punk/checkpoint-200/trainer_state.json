{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 20.0,
  "eval_steps": 100,
  "global_step": 200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 1.0,
      "grad_norm": 19.58755874633789,
      "learning_rate": 9.55e-05,
      "loss": 66.6015,
      "step": 10
    },
    {
      "epoch": 2.0,
      "grad_norm": 16.69607925415039,
      "learning_rate": 9.15e-05,
      "loss": 56.4417,
      "step": 20
    },
    {
      "epoch": 3.0,
      "grad_norm": 14.417304039001465,
      "learning_rate": 8.7e-05,
      "loss": 51.2687,
      "step": 30
    },
    {
      "epoch": 4.0,
      "grad_norm": 14.027421951293945,
      "learning_rate": 8.2e-05,
      "loss": 48.5749,
      "step": 40
    },
    {
      "epoch": 5.0,
      "grad_norm": 15.167112350463867,
      "learning_rate": 7.7e-05,
      "loss": 47.9478,
      "step": 50
    },
    {
      "epoch": 6.0,
      "grad_norm": 9.095377922058105,
      "learning_rate": 7.2e-05,
      "loss": 47.3773,
      "step": 60
    },
    {
      "epoch": 7.0,
      "grad_norm": 12.485346794128418,
      "learning_rate": 6.7e-05,
      "loss": 47.3181,
      "step": 70
    },
    {
      "epoch": 8.0,
      "grad_norm": 9.478196144104004,
      "learning_rate": 6.2e-05,
      "loss": 47.016,
      "step": 80
    },
    {
      "epoch": 9.0,
      "grad_norm": 7.463597297668457,
      "learning_rate": 5.6999999999999996e-05,
      "loss": 46.7533,
      "step": 90
    },
    {
      "epoch": 10.0,
      "grad_norm": 11.945535659790039,
      "learning_rate": 5.2000000000000004e-05,
      "loss": 46.6787,
      "step": 100
    },
    {
      "epoch": 10.0,
      "eval_runtime": 2.247,
      "eval_samples_per_second": 5.34,
      "eval_steps_per_second": 5.34,
      "step": 100
    },
    {
      "epoch": 11.0,
      "grad_norm": 11.848694801330566,
      "learning_rate": 4.7e-05,
      "loss": 46.4484,
      "step": 110
    },
    {
      "epoch": 12.0,
      "grad_norm": 8.869041442871094,
      "learning_rate": 4.2e-05,
      "loss": 46.4029,
      "step": 120
    },
    {
      "epoch": 13.0,
      "grad_norm": 9.993573188781738,
      "learning_rate": 3.7e-05,
      "loss": 46.1836,
      "step": 130
    },
    {
      "epoch": 14.0,
      "grad_norm": 9.868556022644043,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 46.0586,
      "step": 140
    },
    {
      "epoch": 15.0,
      "grad_norm": 11.435728073120117,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 45.9447,
      "step": 150
    },
    {
      "epoch": 16.0,
      "grad_norm": 11.942995071411133,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 45.4484,
      "step": 160
    },
    {
      "epoch": 17.0,
      "grad_norm": 13.1239652633667,
      "learning_rate": 1.75e-05,
      "loss": 45.4649,
      "step": 170
    },
    {
      "epoch": 18.0,
      "grad_norm": 14.134758949279785,
      "learning_rate": 1.25e-05,
      "loss": 45.3213,
      "step": 180
    },
    {
      "epoch": 19.0,
      "grad_norm": 10.54835033416748,
      "learning_rate": 7.5e-06,
      "loss": 45.3613,
      "step": 190
    },
    {
      "epoch": 20.0,
      "grad_norm": 15.290846824645996,
      "learning_rate": 2.5e-06,
      "loss": 45.175,
      "step": 200
    },
    {
      "epoch": 20.0,
      "eval_runtime": 2.2339,
      "eval_samples_per_second": 5.372,
      "eval_steps_per_second": 5.372,
      "step": 200
    }
  ],
  "logging_steps": 10,
  "max_steps": 200,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 87403468099680.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
